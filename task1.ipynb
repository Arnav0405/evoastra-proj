{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db8eb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "import numpy as np\n",
    "from typing import Dict, Any, Tuple\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "class TunableBahdanauAttention(tf.keras.Model):\n",
    "    \"\"\"Tunable version of BahdanauAttention with configurable parameters\"\"\"\n",
    "    def __init__(self, units, dropout_rate=0.0, activation='tanh'):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.activation = activation\n",
    "        \n",
    "    def call(self, features, hidden, training=None):\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "        \n",
    "        # Apply configurable activation function\n",
    "        if self.activation == 'tanh':\n",
    "            score = tf.nn.tanh(self.W1(features) + self.W2(hidden_with_time_axis))\n",
    "        elif self.activation == 'relu':\n",
    "            score = tf.nn.relu(self.W1(features) + self.W2(hidden_with_time_axis))\n",
    "        else:  # leaky_relu\n",
    "            score = tf.nn.leaky_relu(self.W1(features) + self.W2(hidden_with_time_axis))\n",
    "        \n",
    "        score = self.dropout(score, training=training)\n",
    "        attention_weights = tf.nn.softmax(self.V(score), axis=1)\n",
    "        context_vector = attention_weights * features\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        return context_vector, attention_weights\n",
    "\n",
    "class TunableDecoder(tf.keras.Model):\n",
    "    \"\"\"Tunable version of Decoder with configurable parameters\"\"\"\n",
    "    def __init__(self, embedding_dim, units, vocab_size, dropout_rate=0.0, \n",
    "                 recurrent_dropout=0.0, attention_dropout=0.0, attention_activation='tanh',\n",
    "                 dense_activation='relu', use_layer_norm=False, num_lstm_layers=1):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.num_lstm_layers = num_lstm_layers\n",
    "        self.use_layer_norm = use_layer_norm\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.embedding_dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        \n",
    "        # LSTM layers\n",
    "        self.lstm_layers = []\n",
    "        for i in range(num_lstm_layers):\n",
    "            return_sequences = True if i < num_lstm_layers - 1 else True\n",
    "            return_state = True if i == num_lstm_layers - 1 else False\n",
    "            \n",
    "            lstm = tf.keras.layers.LSTM(\n",
    "                units, \n",
    "                return_sequences=return_sequences, \n",
    "                return_state=return_state,\n",
    "                dropout=dropout_rate,\n",
    "                recurrent_dropout=recurrent_dropout\n",
    "            )\n",
    "            self.lstm_layers.append(lstm)\n",
    "        \n",
    "        # Dense layers\n",
    "        self.fc1 = tf.keras.layers.Dense(units, activation=dense_activation)\n",
    "        self.fc1_dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.fc2 = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "        # Attention mechanism\n",
    "        self.attention = TunableBahdanauAttention(units, attention_dropout, attention_activation)\n",
    "        \n",
    "        # Layer normalization (optional)\n",
    "        if use_layer_norm:\n",
    "            self.layer_norm1 = tf.keras.layers.LayerNormalization()\n",
    "            self.layer_norm2 = tf.keras.layers.LayerNormalization()\n",
    "    \n",
    "    def call(self, x, features, hidden, training=None):\n",
    "        context_vector, attention_weights = self.attention(features, hidden, training=training)\n",
    "        \n",
    "        # Embedding\n",
    "        x = self.embedding(x)\n",
    "        x = self.embedding_dropout(x, training=training)\n",
    "        \n",
    "        # Concatenate context vector with embeddings\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        \n",
    "        # Apply layer normalization if enabled\n",
    "        if self.use_layer_norm:\n",
    "            x = self.layer_norm1(x, training=training)\n",
    "        \n",
    "        # Pass through LSTM layers\n",
    "        states = []\n",
    "        for i, lstm_layer in enumerate(self.lstm_layers):\n",
    "            if i == len(self.lstm_layers) - 1:  # Last layer returns states\n",
    "                x, state_h, state_c = lstm_layer(x, training=training)\n",
    "                states = [state_h, state_c]\n",
    "            else:\n",
    "                x = lstm_layer(x, training=training)\n",
    "        \n",
    "        # Dense layers\n",
    "        x = self.fc1(x)\n",
    "        if self.use_layer_norm:\n",
    "            x = self.layer_norm2(x, training=training)\n",
    "        x = self.fc1_dropout(x, training=training)\n",
    "        x = tf.reshape(x, (-1, x.shape[2]))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x, states[0], attention_weights  # Return hidden state\n",
    "    \n",
    "    def reset_state(self, batch_size):\n",
    "        return tf.zeros((batch_size, self.units))\n",
    "\n",
    "class ImageCaptionHyperModel(kt.HyperModel):\n",
    "    \"\"\"Hypermodel for tuning image captioning model parameters\"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size, cnn_encoder=None):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.cnn_encoder = cnn_encoder\n",
    "    \n",
    "    def build(self, hp):\n",
    "        \"\"\"Build model with hyperparameters\"\"\"\n",
    "        \n",
    "        # Decoder hyperparameters\n",
    "        embedding_dim = hp.Int('embedding_dim', min_value=128, max_value=512, step=64)\n",
    "        units = hp.Int('lstm_units', min_value=256, max_value=1024, step=128)\n",
    "        \n",
    "        # Dropout hyperparameters\n",
    "        dropout_rate = hp.Float('dropout_rate', min_value=0.0, max_value=0.5, step=0.1)\n",
    "        recurrent_dropout = hp.Float('recurrent_dropout', min_value=0.0, max_value=0.3, step=0.1)\n",
    "        attention_dropout = hp.Float('attention_dropout', min_value=0.0, max_value=0.3, step=0.1)\n",
    "        \n",
    "        # Attention mechanism hyperparameters\n",
    "        attention_activation = hp.Choice('attention_activation', ['tanh', 'relu', 'leaky_relu'])\n",
    "        \n",
    "        # Dense layer hyperparameters\n",
    "        dense_activation = hp.Choice('dense_activation', ['relu', 'gelu'])\n",
    "        \n",
    "        # Architecture hyperparameters\n",
    "        use_layer_norm = hp.Boolean('use_layer_norm')\n",
    "        num_lstm_layers = hp.Int('num_lstm_layers', min_value=1, max_value=3)\n",
    "        \n",
    "        # Learning rate\n",
    "        learning_rate = hp.Float('learning_rate', min_value=1e-5, max_value=1e-2, sampling='LOG')\n",
    "        \n",
    "        # Build decoder\n",
    "        decoder = TunableDecoder(\n",
    "            embedding_dim=embedding_dim,\n",
    "            units=units,\n",
    "            vocab_size=self.vocab_size,\n",
    "            dropout_rate=dropout_rate,\n",
    "            recurrent_dropout=recurrent_dropout,\n",
    "            attention_dropout=attention_dropout,\n",
    "            attention_activation=attention_activation,\n",
    "            dense_activation=dense_activation,\n",
    "            use_layer_norm=use_layer_norm,\n",
    "            num_lstm_layers=num_lstm_layers\n",
    "        )\n",
    "        \n",
    "        # Create a wrapper model for training\n",
    "        model = CaptionModelWrapper(self.cnn_encoder, decoder, learning_rate)\n",
    "        \n",
    "        return model\n",
    "\n",
    "class CaptionModelWrapper(tf.keras.Model):\n",
    "    \"\"\"Wrapper model for training with Keras Tuner\"\"\"\n",
    "    \n",
    "    def __init__(self, cnn_encoder, decoder, learning_rate):\n",
    "        super().__init__()\n",
    "        self.cnn_encoder = cnn_encoder\n",
    "        self.decoder_model = decoder\n",
    "        self.loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
    "        \n",
    "        # Optimizer\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        \n",
    "        # Loss function\n",
    "        self.loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "            from_logits=True, reduction='none'\n",
    "        )\n",
    "    \n",
    "    def compile(self, optimizer=None, loss=None, metrics=None, **kwargs):\n",
    "        # Override compile to use custom training\n",
    "        super().compile(**kwargs)\n",
    "    \n",
    "    def loss_function(self, real, pred):\n",
    "        mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "        loss_ = self.loss_object(real, pred)\n",
    "        mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "        loss_ *= mask\n",
    "        return tf.reduce_mean(loss_)\n",
    "    \n",
    "    @tf.function\n",
    "    def train_step(self, data):\n",
    "        img_tensor, target = data\n",
    "        \n",
    "        loss = 0\n",
    "        hidden = self.decoder_model.reset_state(batch_size=target.shape[0])\n",
    "        dec_input = tf.expand_dims([1] * target.shape[0], 1)  # Assuming start token is 1\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            features = self.cnn_encoder(img_tensor, training=False)  # CNN frozen\n",
    "            \n",
    "            for i in range(1, target.shape[1]):\n",
    "                predictions, hidden, _ = self.decoder_model(\n",
    "                    dec_input, features, hidden, training=True\n",
    "                )\n",
    "                loss += self.loss_function(target[:, i], predictions)\n",
    "                dec_input = tf.expand_dims(target[:, i], 1)\n",
    "        \n",
    "        total_loss = loss / int(target.shape[1])\n",
    "        \n",
    "        # Only train decoder variables\n",
    "        trainable_vars = self.decoder_model.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        \n",
    "        # Update metrics\n",
    "        self.loss_tracker.update_state(total_loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.loss_tracker]\n",
    "\n",
    "class ImageCaptionTuner:\n",
    "    \"\"\"Main hyperparameter tuner class\"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size: int, cnn_encoder, project_name: str = \"image_caption_tuning\"):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.cnn_encoder = cnn_encoder\n",
    "        self.project_name = project_name\n",
    "        self.best_params = None\n",
    "        self.tuner = None\n",
    "    \n",
    "    def create_tuner(self, \n",
    "                    tuner_type: str = 'bayesian',\n",
    "                    max_trials: int = 50,\n",
    "                    executions_per_trial: int = 1,\n",
    "                    directory: str = 'hyperparameter_tuning',\n",
    "                    overwrite: bool = False) -> kt.Tuner:\n",
    "        \"\"\"Create and configure the hyperparameter tuner\"\"\"\n",
    "        \n",
    "        hypermodel = ImageCaptionHyperModel(self.vocab_size, self.cnn_encoder)\n",
    "        \n",
    "        if tuner_type == 'bayesian':\n",
    "            tuner = kt.BayesianOptimization(\n",
    "                hypermodel,\n",
    "                objective='loss',\n",
    "                max_trials=max_trials,\n",
    "                executions_per_trial=executions_per_trial,\n",
    "                directory=directory,\n",
    "                project_name=self.project_name,\n",
    "                overwrite=overwrite\n",
    "            )\n",
    "        elif tuner_type == 'random':\n",
    "            tuner = kt.RandomSearch(\n",
    "                hypermodel,\n",
    "                objective='loss',\n",
    "                max_trials=max_trials,\n",
    "                executions_per_trial=executions_per_trial,\n",
    "                directory=directory,\n",
    "                project_name=self.project_name,\n",
    "                overwrite=overwrite\n",
    "            )\n",
    "        elif tuner_type == 'hyperband':\n",
    "            tuner = kt.Hyperband(\n",
    "                hypermodel,\n",
    "                objective='loss',\n",
    "                max_epochs=10,\n",
    "                factor=3,\n",
    "                directory=directory,\n",
    "                project_name=self.project_name,\n",
    "                overwrite=overwrite\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported tuner type: {tuner_type}\")\n",
    "        \n",
    "        self.tuner = tuner\n",
    "        return tuner\n",
    "    \n",
    "    def search(self, \n",
    "               train_dataset,\n",
    "               validation_dataset=None,\n",
    "               epochs: int = 10,\n",
    "               callbacks: list = None) -> None:\n",
    "        \"\"\"Run hyperparameter search\"\"\"\n",
    "        \n",
    "        if self.tuner is None:\n",
    "            raise ValueError(\"Tuner not created. Call create_tuner() first.\")\n",
    "        \n",
    "        # Default callbacks\n",
    "        if callbacks is None:\n",
    "            callbacks = [\n",
    "                tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n",
    "                tf.keras.callbacks.ReduceLROnPlateau(factor=0.2, patience=2)\n",
    "            ]\n",
    "        \n",
    "        print(f\"Starting hyperparameter search with {self.tuner.max_trials} trials...\")\n",
    "        \n",
    "        self.tuner.search(\n",
    "            train_dataset,\n",
    "            validation_data=validation_dataset,\n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        print(\"Hyperparameter search completed!\")\n",
    "    \n",
    "    def get_best_hyperparameters(self, num_trials: int = 1) -> Dict[str, Any]:\n",
    "        \"\"\"Get the best hyperparameters from the search\"\"\"\n",
    "        \n",
    "        if self.tuner is None:\n",
    "            raise ValueError(\"No tuner found. Run search() first.\")\n",
    "        \n",
    "        best_hps = self.tuner.get_best_hyperparameters(num_trials=num_trials)\n",
    "        self.best_params = best_hps[0].values if best_hps else None\n",
    "        \n",
    "        return self.best_params\n",
    "    \n",
    "    def get_best_model(self):\n",
    "        \"\"\"Get the best model from the search\"\"\"\n",
    "        \n",
    "        if self.tuner is None:\n",
    "            raise ValueError(\"No tuner found. Run search() first.\")\n",
    "        \n",
    "        return self.tuner.get_best_models(num_models=1)[0]\n",
    "    \n",
    "    def build_best_model(self) -> Tuple[TunableDecoder, Dict[str, Any]]:\n",
    "        \"\"\"Build the best model with optimal hyperparameters\"\"\"\n",
    "        \n",
    "        best_params = self.get_best_hyperparameters()\n",
    "        \n",
    "        if best_params is None:\n",
    "            raise ValueError(\"No best parameters found. Run search() first.\")\n",
    "        \n",
    "        # Build decoder with best parameters\n",
    "        decoder = TunableDecoder(\n",
    "            embedding_dim=best_params['embedding_dim'],\n",
    "            units=best_params['lstm_units'],\n",
    "            vocab_size=self.vocab_size,\n",
    "            dropout_rate=best_params['dropout_rate'],\n",
    "            recurrent_dropout=best_params['recurrent_dropout'],\n",
    "            attention_dropout=best_params['attention_dropout'],\n",
    "            attention_activation=best_params['attention_activation'],\n",
    "            dense_activation=best_params['dense_activation'],\n",
    "            use_layer_norm=best_params['use_layer_norm'],\n",
    "            num_lstm_layers=best_params['num_lstm_layers']\n",
    "        )\n",
    "        \n",
    "        return decoder, best_params\n",
    "    \n",
    "    def save_results(self, filepath: str = None):\n",
    "        \"\"\"Save tuning results to file\"\"\"\n",
    "        \n",
    "        if filepath is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filepath = f\"tuning_results_{timestamp}.json\"\n",
    "        \n",
    "        results = {\n",
    "            'best_hyperparameters': self.get_best_hyperparameters(),\n",
    "            'tuner_summary': self.tuner.results_summary() if self.tuner else None,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump(results, f, indent=2, default=str)\n",
    "        \n",
    "        print(f\"Results saved to {filepath}\")\n",
    "    \n",
    "    def results_summary(self):\n",
    "        \"\"\"Print summary of tuning results\"\"\"\n",
    "        \n",
    "        if self.tuner is None:\n",
    "            print(\"No tuner found. Run search() first.\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"HYPERPARAMETER TUNING RESULTS SUMMARY\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Best hyperparameters\n",
    "        best_params = self.get_best_hyperparameters()\n",
    "        if best_params:\n",
    "            print(\"\\nBest Hyperparameters:\")\n",
    "            print(\"-\" * 30)\n",
    "            for param, value in best_params.items():\n",
    "                print(f\"{param}: {value}\")\n",
    "        \n",
    "        # Tuner summary\n",
    "        print(f\"\\nTotal trials completed: {len(self.tuner.oracle.trials)}\")\n",
    "        self.tuner.results_summary()\n",
    "\n",
    "# Example usage function\n",
    "def example_usage(vocab_size):\n",
    "    \"\"\"Example of how to use the ImageCaptionTuner\"\"\"\n",
    "    \n",
    "    # Assuming you have your CNN encoder and dataset ready\n",
    "    cnn_encoder = create_cnn_encoder()  # Your existing CNN encoder\n",
    "    \n",
    "    # Create tuner\n",
    "    tuner = ImageCaptionTuner(vocab_size, cnn_encoder)\n",
    "    \n",
    "    # Create and configure the hyperparameter tuner\n",
    "    kt_tuner = tuner.create_tuner(\n",
    "        tuner_type='bayesian',\n",
    "        max_trials=30,\n",
    "        directory='tuning_results'\n",
    "    )\n",
    "    \n",
    "    # Run search\n",
    "    tuner.search(\n",
    "        train_dataset,  # Your training dataset\n",
    "        validation_dataset,  # Your validation dataset\n",
    "        epochs=5\n",
    "    )\n",
    "    \n",
    "    # Get results\n",
    "    best_decoder, best_params = tuner.build_best_model()\n",
    "    tuner.results_summary()\n",
    "    tuner.save_results()\n",
    "\n",
    "    return best_decoder, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebb5cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_encoder():\n",
    "    base_model = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet')\n",
    "    base_model.trainable = False\n",
    "    output = base_model.output\n",
    "    output = tf.keras.layers.Reshape((-1, output.shape[-1]))(output)  # (batch, H*W, features)\n",
    "    return tf.keras.Model(inputs=base_model.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e541bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, features, hidden):\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "        score = tf.nn.tanh(self.W1(features) + self.W2(hidden_with_time_axis))\n",
    "        attention_weights = tf.nn.softmax(self.V(score), axis=1)\n",
    "        context_vector = attention_weights * features\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        return context_vector, attention_weights\n",
    "\n",
    "\n",
    "class CaptionDecoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, units, dropout_rate=0.0):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = tf.keras.layers.LSTM(units, return_sequences=True, return_state=True, dropout=dropout_rate)\n",
    "        self.fc1 = tf.keras.layers.Dense(units, activation='tanh')\n",
    "        self.fc2 = tf.keras.layers.Dense(vocab_size)\n",
    "        self.attention = BahdanauAttention(units)\n",
    "\n",
    "    def call(self, x, features, hidden):\n",
    "        context_vector, attn_weights = self.attention(features, hidden)\n",
    "        x = self.embedding(x)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        output, state_h, state_c = self.lstm(x)\n",
    "        x = self.fc1(output)\n",
    "        x = tf.reshape(x, (-1, x.shape[2]))\n",
    "        logits = self.fc2(x)\n",
    "        return logits, state_h, attn_weights\n",
    "\n",
    "    def reset_state(self, batch_size):\n",
    "        return tf.zeros((batch_size, self.units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05163d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaptionHyperModel(HyperModel):\n",
    "    def __init__(self, vocab_size):\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "    def build(self, hp):\n",
    "        # Tune hyperparameters\n",
    "        embedding_dim = hp.Int(\"embedding_dim\", min_value=128, max_value=512, step=64)\n",
    "        units = hp.Int(\"lstm_units\", min_value=128, max_value=512, step=64)\n",
    "        dropout_rate = hp.Float(\"dropout\", 0.0, 0.5, step=0.1, default=0.1)\n",
    "        learning_rate = hp.Float(\"lr\", 1e-4, 1e-2, sampling=\"log\")\n",
    "\n",
    "        # Build encoder (frozen)\n",
    "        cnn_encoder = create_cnn_encoder()\n",
    "        cnn_encoder.trainable = False\n",
    "\n",
    "        # Build decoder\n",
    "        decoder = CaptionDecoder(\n",
    "            vocab_size=self.vocab_size,\n",
    "            embedding_dim=embedding_dim,\n",
    "            units=units,\n",
    "            dropout_rate=dropout_rate\n",
    "        )\n",
    "\n",
    "        # Optimizer\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "        # Store for access later\n",
    "        decoder.cnn_encoder = cnn_encoder\n",
    "        decoder.optimizer = optimizer\n",
    "\n",
    "        return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a25450",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaptionTuner(kt.Tuner):\n",
    "    def run_trial(self, trial, train_data, val_data, epochs=3, steps_per_epoch=50, validation_steps=20):\n",
    "        # Build model from hypermodel\n",
    "        decoder = self.hypermodel.build(trial.hyperparameters)\n",
    "\n",
    "        # Loss function\n",
    "        def compute_loss(real, pred):\n",
    "            mask = tf.not_equal(real, 0)\n",
    "            loss = tf.keras.losses.sparse_categorical_crossentropy(real, pred, from_logits=True, reduction='none')\n",
    "            loss = tf.boolean_mask(loss, mask)\n",
    "            return tf.reduce_mean(loss)\n",
    "\n",
    "        # Training step\n",
    "        @tf.function\n",
    "        def train_step(images, captions):\n",
    "            hidden = decoder.reset_state(batch_size=captions.shape[0])\n",
    "            dec_input = tf.expand_dims([word2idx('<start>')] * captions.shape[0], 1)\n",
    "            total_loss = 0.0\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                features = decoder.cnn_encoder(images, training=False)  # frozen\n",
    "                for t in range(1, captions.shape[1]):\n",
    "                    predictions, hidden, _ = decoder(dec_input, features, hidden)\n",
    "                    loss = compute_loss(captions[:, t], predictions)\n",
    "                    total_loss += loss\n",
    "                    dec_input = tf.expand_dims(captions[:, t], 1)\n",
    "\n",
    "            avg_loss = total_loss / captions.shape[1]\n",
    "            grads = tape.gradient(avg_loss, decoder.trainable_variables)\n",
    "            decoder.optimizer.apply_gradients(zip(grads, decoder.trainable_variables))\n",
    "            return avg_loss\n",
    "\n",
    "        # Validation step\n",
    "        @tf.function\n",
    "        def val_step(images, captions):\n",
    "            hidden = decoder.reset_state(batch_size=captions.shape[0])\n",
    "            dec_input = tf.expand_dims([word2idx('<start>')] * captions.shape[0], 1)\n",
    "            total_loss = 0.0\n",
    "            features = decoder.cnn_encoder(images, training=False)\n",
    "            for t in range(1, captions.shape[1]):\n",
    "                predictions, hidden, _ = decoder(dec_input, features, hidden)\n",
    "                loss = compute_loss(captions[:, t], predictions)\n",
    "                total_loss += loss\n",
    "                dec_input = tf.expand_dims(captions[:, t], 1)\n",
    "            return total_loss / captions.shape[1]\n",
    "\n",
    "        # Run epochs\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"Trial {trial.trial_id}, Epoch {epoch + 1}/{epochs}\")\n",
    "\n",
    "            # Training\n",
    "            train_loss = 0.0\n",
    "            for step, (images, captions) in enumerate(train_data.take(steps_per_epoch)):\n",
    "                loss = train_step(images, captions)\n",
    "                train_loss += loss\n",
    "            avg_train_loss = float(train_loss / steps_per_epoch)\n",
    "\n",
    "            # Validation\n",
    "            val_loss = 0.0\n",
    "            for step, (images, captions) in enumerate(val_data.take(validation_steps)):\n",
    "                loss = val_step(images, captions)\n",
    "                val_loss += loss\n",
    "            avg_val_loss = float(val_loss / validation_steps)\n",
    "\n",
    "            # Report metrics\n",
    "            self.oracle.update_trial(\n",
    "                trial.trial_id,\n",
    "                {\n",
    "                    \"epoch\": epoch + 1,\n",
    "                    \"train_loss\": avg_train_loss,\n",
    "                    \"val_loss\": avg_val_loss,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        self.save_model(trial.trial_id, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29937369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hypermodel\n",
    "hypermodel = CaptionHyperModel(vocab_size=18366)\n",
    "\n",
    "# Create tuner with Bayesian Optimization\n",
    "tuner = CaptionTuner(\n",
    "    oracle=kt.oracles.BayesianOptimization(\n",
    "        objective=kt.Objective(\"val_loss\", \"min\"),\n",
    "        max_trials=15,\n",
    "        seed=42,\n",
    "        num_initial_points=3,\n",
    "    ),\n",
    "    hypermodel=hypermodel,\n",
    "    directory=\"tuner_results\",\n",
    "    project_name=\"image_captioning_modern\",\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "# Start search\n",
    "tuner.search(\n",
    "    train_data=train_dataset,\n",
    "    val_data=val_dataset,\n",
    "    epochs=3,\n",
    "    steps_per_epoch=50,\n",
    "    validation_steps=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47687756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best hyperparameters\n",
    "best_hp = tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "print(\"ðŸ”¤ Best Hyperparameters:\")\n",
    "for param in best_hp.values:\n",
    "    print(f\"  {param}: {best_hp.get(param)}\")\n",
    "\n",
    "# Get best model\n",
    "best_decoder = tuner.get_best_models(num_models=1)[0]\n",
    "best_cnn_encoder = best_decoder.cnn_encoder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
